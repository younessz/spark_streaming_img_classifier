
# load images from online in a single folder preferably train test


# using Spark Python MLIB random forest

# read one image to start, parse and get a spark dataframe

# fit a random forest from Spark or similar to the flattened array (multiple
# columns 1 per pixel i.e. length * height)

# fit on train data and save the model as a file as part of the project

# MAKe a java class processor under folder main
# this class contains the main() method

# then run the spark streaming app
# read images from the whole folder test (i.e. convert Py code to Java)
# => for each image flattened get prediction from the trained e.g.
# random forest model

# print the results to the terminal {id image: classification ie. digits}
# and return a map out of that (i.e. the print is to check what we have
# and the map can be used for other pipelines
